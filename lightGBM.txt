from google.colab import drive
drive.mount('/content/drive')
from glob import glob
import cv2
import matplotlib.pyplot as plt
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
import lightgbm as lgb

import tensorflow as tf
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model

images_path = {}
images_path["benign"] = glob("/content/drive/MyDrive/BreaKHis_v1/histology_slides/breast/benign/SOB/*/*/40X/*.png")
images_path["malignant"] = glob("/content/drive/MyDrive/BreaKHis_v1/histology_slides/breast/malignant/SOB/*/*/40X/*.png")
images_class = {
    'benign' : 0,
    'malignant' : 1
}

print(images_path)
X = []
Y = []

for label in images_path:
    for image_path in images_path[label]:
        image = cv2.imread(image_path)
        image = cv2.resize(image,(224, 224))
        X.append(image)
        Y.append(images_class[label])

plt.imshow(X[0])
plt.show()
x = np.array(X)
y = np.array(Y)

# Apply Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True)

datagen.fit(x)

X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=0)

# Use Data Augmentation
X_train_aug = datagen.flow(X_train, Y_train, batch_size=32)
X_test_aug = datagen.flow(X_test, Y_test, batch_size=32)

X_train_aug = np.array([x[0] for x in X_train_aug])
X_test_aug = np.array([x[0] for x in X_test_aug])

# Create base model
base_model = VGG19(include_top=False, input_shape=(224, 224, 3), pooling="avg")
for layer in base_model.layers:
    layer.trainable = False

# Add a custom classification layer
x = base_model.output
x = Flatten()(x)
predictions = Dense(1, activation="sigmoid")(x)

# Model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Train
model.fit(X_train_aug, Y_train, batch_size=32, epochs=20, validation_data=(X_test_aug, Y_test))

# Evaluate
loss, accuracy = model.evaluate(X_test_aug, Y_test)
print(f"Accuracy: {accuracy*100} %")

